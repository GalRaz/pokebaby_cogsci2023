Throughout development, humans are inundated with visual information. Infants and young children constantly decide how much time to spend looking at what is in front of them and when to move on to something else [@haith1980rules; @dweck2017needs; @raz2020learning]. Developmental psychologists have long relied on infants' ability to decide what to look at and for how long, making inferences about infants' mental representations [@aslin2007s; @baillargeon1985object; @fantz1963pattern]. In a typical study measuring looking time, infants are presented with the same stimulus repeatedly until their looking time decreases (habituation). Then, they are presented with a new stimulus, and the change in their looking time is used as evidence for cognitive capacities. Despite extensive use of looking time as a measure, the factors underlying infants' decision to keep looking or look away are not well understood. In this paper, we conduct a direct empirical test of the relationships between prior exposure and looking preferences.

One dominant framework for infant looking is that the dynamics of looking time are governed by the dynamics of learning [@hunter1988multifactor]. This framework has been used to derive qualitative predictions about looking time as a function of prior exposure and stimulus complexity. If infants have sufficient prior exposure to complete
encoding of one stimulus, they should look longer at a novel stimulus
that offers new opportunities to learn, showing a novelty preference. In
contrast, when infants have only limited prior exposure or have partially
encoded one stimulus, they might look at that same stimulus for longer
to learn more about it, showing a familiarity preference.

However, empirical studies that systematically quantify familiarity
preferences for visual stimuli tend to be older, have smaller sample
sizes, and limited or no data available, making them unsuitable for
evaluating the robustness of the phenomenon [e.g., @hunter1983effects; @rose1982familiarity]. Furthermore, this theoretical framework does not include formal criteria to judge the completeness of encoding, limiting the precision of predictions for new experiments. The dynamics in this framework are instead often invoked retroactively, to explain unexpected findings. For example, @johnson2009abstract studied rule learning in 8- and 11-month old infants, finding novelty preferences in 8-month olds in one condition and familiarity preferences in 11-month olds in three others (as well as four conditions with no significant differences). They interpreted these differences post hoc as indicating some combination of greater complexity for certain rules over others and faster encoding by older children.  

To move from post hoc interpretations towards predictive frameworks of
looking time experiments, computational models are beginning to play a
role. Across the cognitive sciences, computational models facilitate
theory-building and provoke more precise formulations of cognitive
phenomena [@guest2021computational; @smaldino2020translate]. For infant looking, formal models of learning have successfully predicted infants'
habituation and subsequent preferences for novel stimuli. However, in contrast to @hunter1988multifactor’s framework, these formal models generally do not predict that infants will show familiarity preferences when given limited learning experience [@sirois2002models]. 

In a recent example of such a model, @cao2022habituation proposed that habituation and novelty preferences could be explained by a rational learner that takes noisy perceptual samples to maximize information gain (RANCH). This model accurately predicted adult looking time patterns in a self-paced habituation paradigm, reproducing both habituation and novelty preferences. However, RANCH does not predict familiarity
preferences at any stage of encoding, because its policy to
maximize information gain would always prioritize learning about a novel
stimulus over a repeated familiar stimulus, just to varying degrees.

By contrast, other models do seem to contain either indirect or direct
predictions of familiarity preference. @kidd2012goldilocks proposed the “Goldilocks effect” – infants’ tendency to focus on things that are neither too simple nor too complex - as a formal account of infant looking. In this work, an ideal learner model tracked the relative probability of objects appearing in specific locations in a continuous stream of events, and infants’ probability of looking away from each successive object had a U-shaped link to the models’ surprisal. It has been suggested that infants’ tendency to stay most engaged with moderately predictable events may be a reflection of familiarity preferences at early stages of encoding. 

A more recent formal model used rational information gathering agents to explain infant looking behaviors, and directly predicted familiarity preferences [@karni2022]. This model is similar to RANCH in that its learning policy considers information gain, but it also considers another source of value (i.e. information "need": how frequently the information about each stimulus will be used). A trade-off between information gain and information need generates non-monotonic changes in looking time, which predict both familiarity preferences and novelty preferences. 

To evaluate and compare the predictions of these different model types, however, it is necessary to have quantitative estimates of habituation, novelty preferences, and familiarity preferences from behavioral data. Under what circumstances do familiar stimuli evoke  longer looking, following limited exposure and thus potentially partial encoding?

In this paper, we aim to offer a stronger empirical foundation for understanding how the duration of exposure influences looking preferences. We conducted experiments with preschoolers and infants to test the conditions under which familiarity preferences could be elicited. For preschoolers, we adapted a self-paced looking time paradigm that was previously used to capture habituation and novelty preferences in adults [@cao2022habituation]. For infants, we developed a new within-participants measurement paradigm. This set of experiments allows us to directly investigate whether familiarity preferences arise when learners have limited experience with stimuli. To preview, while preschoolers and infants show both habituation and novelty preferences in our paradigm, we found no evidence for familiarity preferences in either preschoolers or infants.